#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cä»£ç ç´¢å¼•å·¥å…· MCP Server (å·¥ä½œç‰ˆ)

çœŸæ­£èƒ½è¿è¡Œçš„ç‰ˆæœ¬ï¼Œä¿®å¤æ‰€æœ‰å·²çŸ¥é—®é¢˜
"""

import asyncio
import sys
import os
from pathlib import Path

# è®¾ç½®ç¼–ç ç¯å¢ƒå˜é‡
os.environ['PYTHONIOENCODING'] = 'utf-8'

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

try:
    from mcp.server import Server
    from mcp.types import Tool, TextContent
    import mcp.types as types
    from mcp.server.stdio import stdio_server
except ImportError as e:
    print(f"MCP å¯¼å…¥å¤±è´¥: {e}", file=sys.stderr)
    print("è¯·è¿è¡Œ: pip install mcp", file=sys.stderr)
    sys.exit(1)

# åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
server = Server("c-code-indexer")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """è¿”å›å¯ç”¨çš„å·¥å…·åˆ—è¡¨"""
    return [
        Tool(
            name="build_c_index",
            description="ä¸ºCè¯­è¨€é¡¹ç›®æ„å»ºä»£ç ç´¢å¼•",
            inputSchema={
                "type": "object",
                "properties": {
                    "project_path": {
                        "type": "string",
                        "description": "Cé¡¹ç›®çš„æ ¹ç›®å½•è·¯å¾„"
                    },
                    "force_rebuild": {
                        "type": "boolean", 
                        "description": "æ˜¯å¦å¼ºåˆ¶é‡å»ºç´¢å¼•",
                        "default": False
                    }
                },
                "required": ["project_path"]
            }
        ),
        Tool(
            name="search_code_semantic",
            description="ä½¿ç”¨è‡ªç„¶è¯­è¨€è¯­ä¹‰æœç´¢Cä»£ç ç¬¦å·",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "è‡ªç„¶è¯­è¨€æœç´¢æŸ¥è¯¢ï¼Œä¾‹å¦‚ï¼š'å†…å­˜åˆ†é…å‡½æ•°'ã€'JSONè§£æ'ç­‰"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 50
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="search_symbol_exact",
            description="ç²¾ç¡®æœç´¢ç‰¹å®šçš„ç¬¦å·åç§°",
            inputSchema={
                "type": "object",
                "properties": {
                    "symbol_name": {
                        "type": "string",
                        "description": "è¦æœç´¢çš„ç¡®åˆ‡ç¬¦å·åç§°ï¼Œä¾‹å¦‚ï¼š'malloc'ã€'cJSON_Parse'ç­‰"
                    }
                },
                "required": ["symbol_name"]
            }
        ),
        Tool(
            name="get_project_statistics",
            description="è·å–é¡¹ç›®çš„ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {},
                "additionalProperties": False
            }
        ),
        Tool(
            name="get_symbols_by_type",
            description="æŒ‰ç±»å‹è·å–ç¬¦å·åˆ—è¡¨",
            inputSchema={
                "type": "object",
                "properties": {
                    "symbol_type": {
                        "type": "string",
                        "enum": ["function", "structure", "variable", "macro", "typedef", "enum"],
                        "description": "è¦è·å–çš„ç¬¦å·ç±»å‹"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶",
                        "default": 20,
                        "minimum": 1,
                        "maximum": 100
                    }
                },
                "required": ["symbol_type"]
            }
        ),
        Tool(
            name="analyze_function_complexity",
            description="åˆ†æå‡½æ•°å¤æ‚åº¦",
            inputSchema={
                "type": "object",
                "properties": {
                    "function_name": {
                        "type": "string",
                        "description": "è¦åˆ†æçš„å‡½æ•°åç§°"
                    }
                },
                "required": ["function_name"]
            }
        ),
        Tool(
            name="get_callees",
            description="æ ¹æ®ç¬¦å·IDæŸ¥è¯¢è¢«è°ƒå‡½æ•°ï¼ˆå¯æŒ‡å®šæ·±åº¦ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "symbol_id": {"type": "string", "description": "èµ·å§‹ç¬¦å·ID"},
                    "depth": {"type": "integer", "default": 1}
                },
                "required": ["symbol_id"]
            }
        ),
        Tool(
            name="get_callers",
            description="æ ¹æ®ç¬¦å·IDæŸ¥è¯¢è°ƒç”¨è€…ï¼ˆå¯æŒ‡å®šæ·±åº¦ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "symbol_id": {"type": "string", "description": "ç›®æ ‡ç¬¦å·ID"},
                    "depth": {"type": "integer", "default": 1}
                },
                "required": ["symbol_id"]
            }
        ),
        Tool(
            name="smart_query_index",
            description="æ™ºèƒ½æŸ¥è¯¢ä»£ç ç´¢å¼• - å¤§æ¨¡å‹ä¸“ç”¨å¿«é€ŸæŸ¥è¯¢æ¥å£",
            inputSchema={
                "type": "object",
                "properties": {
                    "index_dir": {
                        "type": "string",
                        "description": "ç´¢å¼•ç›®å½•è·¯å¾„"
                    },
                    "query_type": {
                        "type": "string",
                        "description": "æŸ¥è¯¢ç±»å‹",
                        "enum": ["overview", "search", "function_details", "file_symbols", "by_type", "findings", "stats", "location"]
                    },
                    "query": {
                        "type": "string",
                        "description": "æŸ¥è¯¢å†…å®¹"
                    },
                    "symbol_type": {
                        "type": "string",
                        "description": "ç¬¦å·ç±»å‹è¿‡æ»¤",
                        "enum": ["function", "structure", "variable", "macro"]
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ç»“æœæ•°é‡é™åˆ¶",
                        "default": 20
                    }
                },
                "required": ["index_dir", "query_type"]
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[types.TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    try:
        if name == "build_c_index":
            return await build_c_index(arguments)
        elif name == "search_code_semantic":
            return await search_code_semantic(arguments)
        elif name == "search_symbol_exact":
            return await search_symbol_exact(arguments)
        elif name == "get_project_statistics":
            return await get_project_statistics(arguments)
        elif name == "get_symbols_by_type":
            return await get_symbols_by_type(arguments)
        elif name == "analyze_function_complexity":
            return await analyze_function_complexity(arguments)
        elif name == "get_callees":
            return await get_callees(arguments)
        elif name == "get_callers":
            return await get_callers(arguments)
        elif name == "smart_query_index":
            return await smart_query_index(arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
        )]

async def build_c_index(args: dict) -> list[types.TextContent]:
    """æ„å»ºCä»£ç ç´¢å¼• - ä½¿ç”¨é«˜æ•ˆå¹¶è¡Œåˆ†æå¼•æ“"""
    project_path = args["project_path"]
    force_rebuild = args.get("force_rebuild", False)

    if not Path(project_path).exists():
        return [types.TextContent(
            type="text",
            text=f"âŒ é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}"
        )]

    try:
        # ä½¿ç”¨æ–°çš„é«˜æ•ˆç´¢å¼•å™¨
        try:
            from src.indexer.efficient_c_indexer import EfficientCIndexer
            from src.utils.progress_tracker import get_progress_tracker

            # åˆ›å»ºç´¢å¼•å™¨
            indexer = EfficientCIndexer()

            # è¿›åº¦æ¶ˆæ¯æ”¶é›†
            progress_messages = []
            last_message_time = time.time()

            def progress_callback(message: str):
                """è¿›åº¦å›è°ƒå‡½æ•° - å®æ—¶æ˜¾ç¤ºåˆ°MCP"""
                nonlocal last_message_time
                current_time = time.time()

                progress_messages.append(f"[{time.strftime('%H:%M:%S')}] {message}")

                # å®æ—¶è¾“å‡º (æ¯5ç§’æˆ–é‡è¦æ¶ˆæ¯)
                if current_time - last_message_time > 5 or any(keyword in message for keyword in ['å®Œæˆ', 'å¤±è´¥', 'å¼€å§‹', 'âœ…', 'âŒ', 'ğŸ‰']):
                    print(f"[PROGRESS] {message}", flush=True)
                    last_message_time = current_time

            # å¼€å§‹æ„å»ºç´¢å¼•
            if progress_callback:
                progress_callback(f"ğŸš€ å¯åŠ¨é«˜æ•ˆå¹¶è¡Œåˆ†æå¼•æ“...")
                progress_callback(f"ğŸ“Š é…ç½®: 16GBå†…å­˜, 4å°æ—¶è¶…æ—¶, 12ä¸ªå¹¶è¡Œå·¥ä½œçº¿ç¨‹")

            result = indexer.build_index(
                Path(project_path),
                force_rebuild=force_rebuild,
                progress_callback=progress_callback
            )
            
            # è·å–æœ€ç»ˆè¿›åº¦æ‘˜è¦
            tracker = get_progress_tracker(Path(project_path).name)
            final_summary = tracker.get_progress_summary()

            # æ ¼å¼åŒ–æ€§èƒ½ä¿¡æ¯
            performance = result.get('performance', {})
            symbols_by_type = result.get('symbols_by_type', {})

            return [types.TextContent(
                type="text",
                text=f"""âœ… é«˜æ•ˆCä»£ç ç´¢å¼•æ„å»ºå®Œæˆ!

{final_summary}

ğŸ“Š **ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯**:
   ğŸ“ é¡¹ç›®è·¯å¾„: {project_path}
   ğŸ“‚ ç´¢å¼•è¾“å‡ºç›®å½•: {result.get('output_directory', 'N/A')}
   ğŸ”¢ æ€»ç¬¦å·æ•°: {result.get('total_symbols', 0)}
   ğŸ¯ å‡½æ•°æ•°é‡: {symbols_by_type.get('function', 0)}
   ğŸ—ï¸ ç»“æ„ä½“æ•°é‡: {symbols_by_type.get('structure', 0)}
   ğŸ“¦ å˜é‡æ•°é‡: {symbols_by_type.get('variable', 0)}
   âš™ï¸ å®å®šä¹‰æ•°é‡: {symbols_by_type.get('macro', 0)}
   ğŸ” é™æ€åˆ†æå‘ç°: {result.get('total_findings', 0)}

ğŸ“ˆ **æ€§èƒ½ä¿¡æ¯**:
   â±ï¸ æ€»æ„å»ºæ—¶é—´: {result.get('build_duration', 0):.2f}ç§’
   ğŸ’¾ å†…å­˜å³°å€¼: {performance.get('peak_memory_mb', 0):.1f}MB
   âœ… æˆåŠŸåˆ†æå™¨: {performance.get('successful_analyzers', 0)}ä¸ª
   âŒ å¤±è´¥åˆ†æå™¨: {performance.get('failed_analyzers', 0)}ä¸ª
   ğŸ”§ ä½¿ç”¨çš„åˆ†æå™¨: {', '.join(result.get('successful_analyzers', []))}

ğŸ“‚ **ç´¢å¼•ç»“æ„**:
   ğŸ“‹ ç¬¦å·æ•°æ®: {result.get('index_structure', {}).get('symbols_dir', 'N/A')}
   ğŸ” åˆ†æç»“æœ: {result.get('index_structure', {}).get('analysis_dir', 'N/A')}
   ğŸ“Š å…ƒæ•°æ®: {result.get('index_structure', {}).get('metadata_dir', 'N/A')}
   ğŸ§  å‘é‡ç´¢å¼•: {result.get('index_structure', {}).get('vectors_dir', 'N/A')}
   ğŸ•¸ï¸ å›¾ç´¢å¼•: {result.get('index_structure', {}).get('graphs_dir', 'N/A')}

ğŸ“‹ **æœ€è¿‘æ„å»ºè¿‡ç¨‹** (æœ€å10æ¡):
{chr(10).join(progress_messages[-10:]) if progress_messages else 'æ— è¯¦ç»†æ—¥å¿—'}

ğŸ‰ **ç´¢å¼•å·²å°±ç»ªï¼** å¤§æ¨¡å‹ç°åœ¨å¯ä»¥å¿«é€ŸæŸ¥è¯¢å’Œåˆ†æä»£ç äº†ï¼

ğŸ’¡ **ä½¿ç”¨æç¤º**:
   - ä½¿ç”¨ `search_code_semantic` è¿›è¡Œè¯­ä¹‰æœç´¢
   - ä½¿ç”¨ `search_symbol_exact` è¿›è¡Œç²¾ç¡®ç¬¦å·æŸ¥æ‰¾
   - ä½¿ç”¨ `get_project_statistics` æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡
   - ç´¢å¼•æ•°æ®å·²ç»Ÿä¸€ä¿å­˜åœ¨: {result.get('output_directory', 'N/A')}"""
            )]
            
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
            c_files = list(Path(project_path).rglob("*.c")) + list(Path(project_path).rglob("*.h"))
            file_count = len(c_files)
            
            return [types.TextContent(
                type="text",
                text=f"""ğŸ“‹ **æ¨¡æ‹Ÿç´¢å¼•æ„å»ºå®Œæˆ** (éœ€è¦å®Œæ•´å®‰è£…æ‰èƒ½ä½¿ç”¨å®é™…åŠŸèƒ½)

ğŸ“ é¡¹ç›®è·¯å¾„: {project_path}
ğŸ”„ å¼ºåˆ¶é‡å»º: {force_rebuild}
ğŸ“„ å‘ç°C/Hæ–‡ä»¶: {file_count} ä¸ª

ğŸ’¡ **è¦ä½¿ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·ç¡®ä¿**:
1. æ‰€æœ‰ä¾èµ–å·²å®‰è£…: `pip install -r requirements.txt`
2. é¡¹ç›®ç»“æ„å®Œæ•´
3. Pythonç¯å¢ƒæ­£ç¡®é…ç½®

ğŸ“š **å®‰è£…å®Œæˆåå¯ä»¥**:
- ğŸ” è¯­ä¹‰æœç´¢: "å†…å­˜åˆ†é…ç›¸å…³çš„å‡½æ•°"
- ğŸ¯ ç²¾ç¡®æœç´¢: "malloc", "free"
- ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯
- ğŸ“ æŒ‰ç±»å‹æµè§ˆç¬¦å·"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {str(e)}\n\nè¯·æ£€æŸ¥é¡¹ç›®è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ˜¯å¦åŒ…å«Cæºä»£ç æ–‡ä»¶ã€‚"
        )]

async def search_code_semantic(args: dict) -> list[types.TextContent]:
    """è¯­ä¹‰æœç´¢ä»£ç """
    query = args["query"]
    limit = args.get("limit", 10)
    
    try:
        try:
            from src.storage import VectorStore
            from src.utils import Config
            
            config = Config()
            vector_store = VectorStore(config)
            results = vector_store.search(query, n_results=limit)
            
            if not results:
                return [types.TextContent(
                    type="text",
                    text=f"ğŸ” **è¯­ä¹‰æœç´¢ç»“æœ**: '{query}'\n\nâŒ æœªæ‰¾åˆ°ç›¸å…³ç¬¦å·ã€‚\n\nğŸ’¡ **å»ºè®®**:\n- å°è¯•æ›´é€šç”¨çš„å…³é”®è¯\n- ç¡®ä¿å·²æ„å»ºé¡¹ç›®ç´¢å¼•\n- æ£€æŸ¥é¡¹ç›®æ˜¯å¦åŒ…å«ç›¸å…³ä»£ç "
                )]
            
            result_text = f"ğŸ” **è¯­ä¹‰æœç´¢ç»“æœ**: '{query}'\næ‰¾åˆ° **{len(results)}** ä¸ªç›¸å…³ç¬¦å·:\n\n"
            
            for i, result in enumerate(results, 1):
                metadata = result['metadata']
                similarity = result.get('similarity', 0.0)
                
                result_text += f"**{i}. {metadata['name']}** ({metadata['type']})\n"
                result_text += f"   ğŸ†” ID: {result.get('id', 'N/A')}\n"
                result_text += f"   ğŸ“„ {metadata['file_path']}:{metadata.get('line_number', '?')}\n"
                result_text += f"   ğŸ“ {metadata.get('declaration', 'N/A')}\n"
                result_text += f"   ğŸ¯ ç›¸ä¼¼åº¦: {similarity:.2%}\n\n"
            
            return [types.TextContent(type="text", text=result_text)]
            
        except ImportError:
            return [types.TextContent(
                type="text",
                text=f"""ğŸ“‹ **æ¨¡æ‹Ÿè¯­ä¹‰æœç´¢**: '{query}'
é™åˆ¶: {limit} ä¸ªç»“æœ

ğŸ’¡ **æ¨¡æ‹Ÿç»“æœ**:
1. **sample_function** (function)
   ğŸ“„ example.c:10
   ğŸ“ void sample_function(int param);
   ğŸ¯ ç›¸ä¼¼åº¦: 85%

2. **utility_helper** (function)  
   ğŸ“„ utils.c:25
   ğŸ“ int utility_helper(const char* input);
   ğŸ¯ ç›¸ä¼¼åº¦: 78%

è¦ä½¿ç”¨å®é™…æœç´¢åŠŸèƒ½ï¼Œè¯·å…ˆæ„å»ºé¡¹ç›®ç´¢å¼•ã€‚"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {str(e)}"
        )]

async def search_symbol_exact(args: dict) -> list[types.TextContent]:
    """ç²¾ç¡®æœç´¢ç¬¦å·"""
    symbol_name = args["symbol_name"]
    
    try:
        try:
            from src.storage import VectorStore
            from src.utils import Config
            
            config = Config()
            vector_store = VectorStore(config)
            results = vector_store.get_symbol_by_name(symbol_name)
            
            if not results:
                return [types.TextContent(
                    type="text",
                    text=f"ğŸ¯ **ç²¾ç¡®æœç´¢ç»“æœ**: '{symbol_name}'\n\nâŒ æœªæ‰¾åˆ°ç¬¦å·ã€‚\n\nğŸ’¡ **å»ºè®®**:\n- æ£€æŸ¥ç¬¦å·åç§°æ‹¼å†™\n- ç¡®ä¿ç¬¦å·å­˜åœ¨äºå·²ç´¢å¼•çš„ä»£ç ä¸­\n- å°è¯•è¯­ä¹‰æœç´¢è·å–ç›¸å…³ç¬¦å·"
                )]
            
            result_text = f"ğŸ¯ **ç²¾ç¡®æœç´¢ç»“æœ**: '{symbol_name}'\næ‰¾åˆ° **{len(results)}** ä¸ªåŒ¹é…:\n\n"
            
            for i, result in enumerate(results, 1):
                metadata = result['metadata']
                result_text += f"**{i}. {metadata['name']}** ({metadata['type']})\n"
                result_text += f"   ğŸ†” ID: {result.get('id', 'N/A')}\n"
                result_text += f"   ğŸ“„ {metadata['file_path']}:{metadata.get('line_number', '?')}\n"
                result_text += f"   ğŸ“ {metadata.get('declaration', 'N/A')}\n\n"
            
            return [types.TextContent(type="text", text=result_text)]
            
        except ImportError:
            return [types.TextContent(
                type="text",
                text=f"""ğŸ“‹ **æ¨¡æ‹Ÿç²¾ç¡®æœç´¢**: '{symbol_name}'

ğŸ’¡ **æ¨¡æ‹Ÿç»“æœ**:
**{symbol_name}** (function)
ğŸ“„ example.c:25  
ğŸ“ int {symbol_name}(const char* input);

è¦ä½¿ç”¨å®é™…æœç´¢åŠŸèƒ½ï¼Œè¯·å…ˆæ„å»ºé¡¹ç›®ç´¢å¼•ã€‚"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ ç²¾ç¡®æœç´¢å¤±è´¥: {str(e)}"
        )]

async def get_project_statistics(args: dict) -> list[types.TextContent]:
    """è·å–é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        try:
            from src.storage import VectorStore
            from src.utils import Config
            
            config = Config()
            vector_store = VectorStore(config)
            stats = vector_store.get_statistics()
            
            result_text = "ğŸ“Š **é¡¹ç›®ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯**:\n\n"
            result_text += f"ğŸ”¢ æ€»ç¬¦å·æ•°: **{stats['total_symbols']}**\n"
            result_text += f"ğŸ§® å‘é‡ç»´åº¦: {stats['embedding_dimension']}\n"
            result_text += f"ğŸ¤– åµŒå…¥æ¨¡å‹: {stats['model_name']}\n\n"
            
            result_text += "ğŸ“ˆ **ç¬¦å·ç±»å‹åˆ†å¸ƒ**:\n"
            for symbol_type, count in stats['symbols_by_type'].items():
                percentage = (count / stats['total_symbols']) * 100 if stats['total_symbols'] > 0 else 0
                result_text += f"   {symbol_type}: **{count}** ä¸ª ({percentage:.1f}%)\n"
            
            return [types.TextContent(type="text", text=result_text)]
            
        except ImportError:
            return [types.TextContent(
                type="text",
                text="""ğŸ“Š **æ¨¡æ‹Ÿé¡¹ç›®ç»Ÿè®¡ä¿¡æ¯**:

ğŸ”¢ æ€»ç¬¦å·æ•°: **128**
ğŸ§® å‘é‡ç»´åº¦: 384  
ğŸ¤– åµŒå…¥æ¨¡å‹: sentence-transformers/all-MiniLM-L6-v2

ğŸ“ˆ **ç¬¦å·ç±»å‹åˆ†å¸ƒ**:
   function: **85** ä¸ª (66.4%)
   structure: **12** ä¸ª (9.4%)
   variable: **31** ä¸ª (24.2%)

ğŸ’¡ è¦æŸ¥çœ‹å®é™…ç»Ÿè®¡ï¼Œè¯·å…ˆæ„å»ºé¡¹ç›®ç´¢å¼•ã€‚"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )]

async def get_symbols_by_type(args: dict) -> list[types.TextContent]:
    """æŒ‰ç±»å‹è·å–ç¬¦å·"""
    symbol_type = args["symbol_type"]
    limit = args.get("limit", 20)
    
    try:
        try:
            from src.storage import VectorStore
            from src.utils import Config
            
            config = Config()
            vector_store = VectorStore(config)
            results = vector_store.search_by_symbol_type(symbol_type, limit=limit)
            
            if not results:
                return [types.TextContent(
                    type="text",
                    text=f"ğŸ“‚ **{symbol_type} ç±»å‹ç¬¦å·**:\n\nâŒ æœªæ‰¾åˆ° {symbol_type} ç±»å‹çš„ç¬¦å·ã€‚"
                )]
            
            result_text = f"ğŸ“‚ **{symbol_type} ç±»å‹ç¬¦å·** (æ˜¾ç¤ºå‰ {len(results)} ä¸ª):\n\n"
            
            for i, result in enumerate(results, 1):
                metadata = result['metadata']
                result_text += f"**{i}. {metadata['name']}**\n"
                result_text += f"   ğŸ“„ {metadata['file_path']}:{metadata.get('line_number', '?')}\n"
                result_text += f"   ğŸ“ {metadata.get('declaration', 'N/A')}\n\n"
            
            return [types.TextContent(type="text", text=result_text)]
            
        except ImportError:
            return [types.TextContent(
                type="text",
                text=f"""ğŸ“‹ **æ¨¡æ‹Ÿ {symbol_type} ç±»å‹ç¬¦å·**:

1. **sample_{symbol_type}**
   ğŸ“„ example.c:10
   ğŸ“ ç¤ºä¾‹å£°æ˜

2. **another_{symbol_type}**
   ğŸ“„ utils.c:25
   ğŸ“ å¦ä¸€ä¸ªç¤ºä¾‹

è¦æŸ¥çœ‹å®é™…ç¬¦å·ï¼Œè¯·å…ˆæ„å»ºé¡¹ç›®ç´¢å¼•ã€‚"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ è·å–ç¬¦å·å¤±è´¥: {str(e)}"
        )]

async def analyze_function_complexity(args: dict) -> list[types.TextContent]:
    """åˆ†æå‡½æ•°å¤æ‚åº¦"""
    function_name = args["function_name"]
    
    try:
        try:
            from src.storage import VectorStore
            from src.utils import Config
            
            config = Config()
            vector_store = VectorStore(config)
            results = vector_store.get_symbol_by_name(function_name)
            
            # è¿‡æ»¤å‡ºå‡½æ•°ç±»å‹çš„ç»“æœ
            functions = [r for r in results if r['metadata'].get('type') == 'function']
            
            if not functions:
                return [types.TextContent(
                    type="text",
                    text=f"ğŸ§® **å‡½æ•°å¤æ‚åº¦åˆ†æ**: '{function_name}'\n\nâŒ æœªæ‰¾åˆ°è¯¥å‡½æ•°ã€‚"
                )]
            
            result_text = f"ğŸ§® **å‡½æ•°å¤æ‚åº¦åˆ†æ**: '{function_name}'\n\n"
            
            for func in functions:
                metadata = func['metadata']
                result_text += f"**ğŸ“ {metadata['name']}**\n"
                result_text += f"   ğŸ“„ {metadata['file_path']}:{metadata.get('line_number', '?')}\n"
                result_text += f"   ğŸ“ {metadata.get('declaration', 'N/A')}\n"
                
                complexity = metadata.get('complexity', 'N/A')
                result_text += f"   ğŸ§® å¤æ‚åº¦è¯„åˆ†: {complexity}\n\n"
            
            return [types.TextContent(type="text", text=result_text)]
            
        except ImportError:
            return [types.TextContent(
                type="text",
                text=f"""ğŸ“‹ **æ¨¡æ‹Ÿå‡½æ•°å¤æ‚åº¦åˆ†æ**: '{function_name}'

**ğŸ“ {function_name}**
ğŸ“„ example.c:25
ğŸ“ int {function_name}(const char* input);
ğŸ§® å¤æ‚åº¦è¯„åˆ†: ä¸­ç­‰ (15)

ğŸ’¡ è¦è·å–å®é™…åˆ†æï¼Œè¯·å…ˆæ„å»ºé¡¹ç›®ç´¢å¼•ã€‚"""
            )]
            
    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ å¤æ‚åº¦åˆ†æå¤±è´¥: {str(e)}"
        )]

async def get_callees(args: dict) -> list[types.TextContent]:
    symbol_id = args["symbol_id"]
    depth = args.get("depth", 1)
    try:
        from src.utils import Config
        from src.storage import GraphStore
        config = Config()
        graph_path = config.get_metadata_dir() / "call_graph.json"
        store = GraphStore(graph_path)
        store.load()
        callees = store.get_callees(symbol_id, depth=depth)
        lines = [f"ğŸ“ Callees(depth={depth}): {len(callees)}"] + [f"- {c}" for c in callees]
        return [types.TextContent(type="text", text="\n".join(lines))]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ è·å–è¢«è°ƒå¤±è´¥: {e}")]

async def get_callers(args: dict) -> list[types.TextContent]:
    symbol_id = args["symbol_id"]
    depth = args.get("depth", 1)
    try:
        from src.utils import Config
        from src.storage import GraphStore
        config = Config()
        graph_path = config.get_metadata_dir() / "call_graph.json"
        store = GraphStore(graph_path)
        store.load()
        callers = store.get_callers(symbol_id, depth=depth)
        lines = [f"ğŸ“£ Callers(depth={depth}): {len(callers)}"] + [f"- {c}" for c in callers]
        return [types.TextContent(type="text", text="\n".join(lines))]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ è·å–è°ƒç”¨è€…å¤±è´¥: {e}")]

async def smart_query_index(args: dict) -> list[types.TextContent]:
    """æ™ºèƒ½æŸ¥è¯¢ä»£ç ç´¢å¼• - å¤§æ¨¡å‹ä¸“ç”¨æ¥å£"""
    index_dir = args["index_dir"]
    query_type = args["query_type"]
    query = args.get("query", "")
    symbol_type = args.get("symbol_type")
    limit = args.get("limit", 20)

    if not Path(index_dir).exists():
        return [types.TextContent(
            type="text",
            text=f"âŒ ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}"
        )]

    try:
        from src.query.smart_index_reader import SmartIndexReader
        reader = SmartIndexReader(index_dir)

        if query_type == "overview":
            # é¡¹ç›®æ¦‚è§ˆ
            overview = reader.get_project_overview()
            text = f"""ğŸ“Š **é¡¹ç›®æ¦‚è§ˆ**

ğŸ“ **é¡¹ç›®è·¯å¾„**: {overview['project_path']}
ğŸ”¢ **æ€»ç¬¦å·æ•°**: {overview['total_symbols']}

ğŸ“‹ **ç¬¦å·åˆ†å¸ƒ**:
   ğŸ¯ å‡½æ•°: {overview['symbols_by_type'].get('function', 0)}
   ğŸ—ï¸ ç»“æ„ä½“: {overview['symbols_by_type'].get('structure', 0)}
   ğŸ“¦ å˜é‡: {overview['symbols_by_type'].get('variable', 0)}
   âš™ï¸ å®: {overview['symbols_by_type'].get('macro', 0)}

ğŸ”§ **åˆ†æå·¥å…·**: {', '.join(overview['successful_analyzers'])}
ğŸ“‚ **æ–‡ä»¶ç»“æ„**: {len(overview['file_structure'])} ä¸ªæ–‡ä»¶

ğŸ¯ **å…³é”®å‡½æ•°** (å‰5ä¸ª):
{chr(10).join([f"   - {f['name']} (å¤æ‚åº¦: {f.get('complexity', 0)})" for f in overview['key_functions'][:5]])}

ğŸ—ï¸ **ä¸»è¦ç»“æ„ä½“** (å‰5ä¸ª):
{chr(10).join([f"   - {s['name']}" for s in overview['main_structures'][:5]])}"""

        elif query_type == "search":
            # ç¬¦å·æœç´¢
            results = reader.search_symbols(query, symbol_type, limit)
            if results:
                text = f"ğŸ” **æœç´¢ç»“æœ**: '{query}' (æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…)\n\n"
                for result in results:
                    text += f"ğŸ“ **{result['name']}** ({result['type']})\n"
                    text += f"   ğŸ“„ {result['file_path']}:{result['line_number']}\n"
                    text += f"   ğŸ“ {result.get('description', 'æ— æè¿°')}\n"
                    text += f"   ğŸ¯ åŒ¹é…åº¦: {result['match_score']}\n\n"
            else:
                text = f"âŒ æœªæ‰¾åˆ°åŒ¹é… '{query}' çš„ç¬¦å·"

        elif query_type == "function_details":
            # å‡½æ•°è¯¦æƒ…
            details = reader.get_function_details(query)
            if details:
                func = details['function']
                text = f"""ğŸ¯ **å‡½æ•°è¯¦æƒ…**: {func['name']}

ğŸ“ **ä½ç½®**: {func['file_path']}:{func['line_number']}
ğŸ”§ **ç±»å‹**: {func.get('return_type', 'unknown')}
ğŸ“ **å‚æ•°**: {', '.join(func.get('parameters', []))}
ğŸ§® **å¤æ‚åº¦**: {details['complexity']}

ğŸ“ **è°ƒç”¨å…³ç³»**:
   ğŸ“¤ è°ƒç”¨è€… ({len(details['callers'])}): {', '.join([c.get('caller', '') for c in details['callers'][:5]])}
   ğŸ“¥ è¢«è°ƒç”¨ ({len(details['callees'])}): {', '.join([c.get('callee', '') for c in details['callees'][:5]])}"""
            else:
                text = f"âŒ æœªæ‰¾åˆ°å‡½æ•°: {query}"

        elif query_type == "file_symbols":
            # æ–‡ä»¶ç¬¦å·
            symbols = reader.get_file_symbols(query)
            text = f"ğŸ“„ **æ–‡ä»¶ç¬¦å·**: {query} (å…± {len(symbols)} ä¸ª)\n\n"
            for symbol in symbols[:limit]:
                text += f"ğŸ“ {symbol['name']} ({symbol['type']}) - è¡Œ {symbol['line_number']}\n"

        elif query_type == "by_type":
            # æŒ‰ç±»å‹æŸ¥è¯¢
            symbols = reader.get_symbols_by_type(query)
            text = f"ğŸ·ï¸ **{query} ç±»å‹ç¬¦å·** (å…± {len(symbols)} ä¸ª)\n\n"
            for symbol in symbols[:limit]:
                text += f"ğŸ“ {symbol['name']} - {symbol['file_path']}:{symbol['line_number']}\n"

        elif query_type == "stats":
            # å¿«é€Ÿç»Ÿè®¡
            stats = reader.get_quick_stats()
            text = f"""ğŸ“Š **é¡¹ç›®ç»Ÿè®¡**

ğŸ“„ æ€»æ–‡ä»¶æ•°: {stats['total_files']}
ğŸ”¢ æ€»ç¬¦å·æ•°: {stats['total_symbols']}
ğŸ¯ å‡½æ•°æ•°: {stats['functions_count']}
ğŸ—ï¸ ç»“æ„ä½“æ•°: {stats['structures_count']}
ğŸ“¦ å˜é‡æ•°: {stats['variables_count']}
âš™ï¸ å®æ•°: {stats['macros_count']}

â±ï¸ åˆ†æè€—æ—¶: {stats['analysis_duration']:.2f}ç§’
âœ… æˆåŠŸåˆ†æå™¨: {stats['successful_analyzers']}ä¸ª
âŒ å¤±è´¥åˆ†æå™¨: {stats['failed_analyzers']}ä¸ª"""

        elif query_type == "location":
            # ä»£ç å®šä½
            locations = reader.find_code_location(query, symbol_type)
            if locations:
                text = f"ğŸ“ **ä»£ç ä½ç½®**: '{query}' (æ‰¾åˆ° {len(locations)} ä¸ª)\n\n"
                for loc in locations:
                    text += f"ğŸ“„ **{loc['file_path']}:{loc['line_number']}**\n"
                    text += f"   ğŸ·ï¸ ç±»å‹: {loc['type']}\n"
                    text += f"   ğŸ“ æè¿°: {loc['description']}\n"
                    text += f"   ğŸ”§ æ¥æº: {loc['source_analyzer']}\n\n"
            else:
                text = f"âŒ æœªæ‰¾åˆ° '{query}' çš„ä»£ç ä½ç½®"

        else:
            text = f"âŒ ä¸æ”¯æŒçš„æŸ¥è¯¢ç±»å‹: {query_type}"

        return [types.TextContent(type="text", text=text)]

    except Exception as e:
        return [types.TextContent(
            type="text",
            text=f"âŒ æ™ºèƒ½æŸ¥è¯¢å¤±è´¥: {str(e)}"
        )]

async def main():
    """ä¸»å‡½æ•° - å¯åŠ¨MCPæœåŠ¡å™¨"""
    # ä½¿ç”¨æ ‡å‡†è¾“å…¥è¾“å‡ºè¿è¡ŒæœåŠ¡å™¨
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream, 
            write_stream, 
            server.create_initialization_options()
        )

if __name__ == "__main__":
    asyncio.run(main()) 